{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Musical and Lyrical Trends at Intelligent Interactive Systems (MIIS)\n",
    "\n",
    "#### Oktay Ozan Güner   -  ID : OZAN_ID\n",
    "#### Juan Miguel Alfonso Habana   -  ID : MIGUEL_ID\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Since 1990, the way people interact with music has evolved significantly. This period marks a transition from the tangible, physical media of CDs and vinyl to the intangible, yet infinitely accessible world of digital music. \n",
    "* How digitalization and streaming have influenced listeners? \n",
    "* How the listening habits have changed over time?\n",
    "\n",
    "We'll examine how our music listening habits have been affected from duration of the songs to the way sentiment of the lyrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing related packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading final version of data\n",
    "data = pd.read_csv(\"Final_Data_20240309.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flagging the lyrics whether they contain chorus part for topic modeling.\n",
    "data[\"Flag_Chorus\"] = data[\"Translated_Lyrics_2\"].apply(lambda x: r\"[Chorus\" in x).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9988, 12263)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing the number of songs that contain chorus part with all songs.\n",
    "data[\"Flag_Chorus\"].sum(), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the songs that contain chorus part.\n",
    "df = data.loc[data[\"Flag_Chorus\"]==1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big girls don't cry (They don't cry)\n",
      "Big girls don't cry (Who said they don't cry?)\n",
      "My girl said goodbye (My-oh-my)\n",
      "My girl didn't cry (I wonder why)\n",
      "Big girls don't cry (They don't cry)\n",
      "Big girls don't cry (Who said they don't cry?)\n",
      "My girl said goodbye (My-oh-my)\n",
      "My girl didn't cry (I wonder why)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_chorus(lyrics):\n",
    "    \"\"\"\n",
    "    Removes unrelated characters from the texts.\n",
    "\n",
    "    Parameters:\n",
    "    - lyrics (str): The raw text that wanted to be extracted chorus part.\n",
    "\n",
    "    Returns:\n",
    "    string: representing chorus part of the raw text.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Regex pattern explanation:\n",
    "    # \\[Chorus - Matches the literal string \"[Chorus\"\n",
    "    # [\\s\\S]*? - Non-greedy match for any character including new lines, allowing for any content (e.g., \" 2\", \" : Kanye\") within the brackets\n",
    "    # \\] - Matches the closing bracket ']'\n",
    "    # (.*?) - Non-greedy match for any characters, capturing them until the next pattern\n",
    "    # (?=\\n\\[|\\Z) - Positive lookahead for either the start of a new section (newline + '[') or end of string (\\Z), without consuming characters\n",
    "    pattern = r'\\[Chorus[\\s\\S]*?\\](.*?)(?=\\n\\[)'\n",
    "    \n",
    "    # Find all non-overlapping matches of the pattern\n",
    "    matches = re.findall(pattern, lyrics, flags=re.DOTALL)\n",
    "    \n",
    "    # Join matches with a newline, trimming leading/trailing whitespace from each match\n",
    "    chorus_parts = \"\\n\".join(match.strip() for match in matches)\n",
    "    return chorus_parts\n",
    "\n",
    "# Example usage:\n",
    "lyrics = \"\"\"\n",
    "[Chorus]\n",
    "Big girls don't cry (They don't cry)\n",
    "Big girls don't cry (Who said they don't cry?)\n",
    "My girl said goodbye (My-oh-my)\n",
    "My girl didn't cry (I wonder why)\n",
    "\n",
    "[Verse 1]\n",
    "(Silly boy) Told my girl we had to break up\n",
    "(Silly boy) Thought that she would call my bluff\n",
    "(Silly boy) But she said to my surprise\n",
    "\"Big girls don't cry\"\n",
    "\n",
    "[Chorus 2]\n",
    "Big girls don't cry (They don't cry)\n",
    "Big girls don't cry (Who said they don't cry?)\n",
    "My girl said goodbye (My-oh-my)\n",
    "My girl didn't cry (I wonder why)\n",
    "\n",
    "[Chorus : Kanye]\n",
    "Big girls don't cry (They don't cry)\n",
    "Big girls don't cry (Who said they don't cry?)\n",
    "My girl said goodbye (My-oh-my)\n",
    "My girl didn't cry (I wonder why)\n",
    "\"\"\"\n",
    "\n",
    "chorus = extract_chorus(lyrics)\n",
    "print(chorus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting chorus parts of the songs.\n",
    "df[\"Chorus\"] = df[\"Translated_Lyrics_2\"].apply(lambda x: \"\\n\".join(list(set(extract_chorus(x).split(\"\\n\")))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting chorus length.\n",
    "df[\"Chorus_Length\"] = df[\"Chorus\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9988.000000\n",
       "mean       83.831398\n",
       "std        60.903900\n",
       "min         0.000000\n",
       "1%          4.870000\n",
       "5%         18.000000\n",
       "10%        27.000000\n",
       "50%        68.000000\n",
       "max       497.000000\n",
       "Name: Chorus_Length, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking chorus length distribution\n",
    "df[\"Chorus_Length\"].describe([0.01,0.05,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing choruses that the chorus length equal to zero.\n",
    "df2 = df[df[\"Chorus_Length\"]!=0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(raw_lyrics:str):\n",
    "  \"\"\"\n",
    "  Removes unrelated characters from the texts.\n",
    "\n",
    "  Parameters:\n",
    "  - raw_lyrics (str): The raw text that wanted to be removed unrelated characters.\n",
    "\n",
    "  Returns:\n",
    "  string: representing clean version of the raw text.\n",
    "  \"\"\"\n",
    "\n",
    "    # Regex pattern to match section markers\n",
    "    pattern = r'\\[.+]'\n",
    "\n",
    "    # Replace section markers with an empty string\n",
    "    cleaned_lyrics = re.sub(pattern, '', raw_lyrics)\n",
    "\n",
    "    # Remove leading and trailing whitespace and newlines\n",
    "    cleaned_lyrics = cleaned_lyrics.strip()\n",
    "\n",
    "    return cleaned_lyrics\n",
    "\n",
    "\n",
    "def text_to_embeds(model, text:str, model_sequence_length:int, overlap:int):\n",
    "  \"\"\"\n",
    "  Converts texts into chunks regarding to model sequence length. Then gets embedding representations of them by using average pooling.\n",
    "\n",
    "  Parameters:\n",
    "  - text (str): The texts that wanted to be represented as embedding.\n",
    "  - model_sequence_length (int): The maximum sequence length of the model used.\n",
    "  - overlap (int): The number of words at the end of one text chunk that will be included at the beginning of the next chunk when splitting the input text into segments for embedding. This parameter ensures continuity and contextual connection between consecutive chunks, especially important for maintaining semantic integrity in natural language processing tasks.\n",
    "  \n",
    "  Returns:\n",
    "  numpy array: representing texts as embeddings.\n",
    "  \"\"\"  \n",
    "  \n",
    "  splitted_text = text.split()\n",
    "  chunks = []\n",
    "  if len(splitted_text) > model_sequence_length:\n",
    "    for i in range(0, len(splitted_text), model_sequence_length-overlap):\n",
    "      chunk = splitted_text[i:i+model_sequence_length]\n",
    "      chunks.append(chunk)\n",
    "\n",
    "      chunk_texts = [\" \".join(c) for c in chunks]\n",
    "\n",
    "      embeddings = [model.encode(chunk_text, convert_to_tensor=True) for chunk_text in chunk_texts]\n",
    "      embeddings = np.mean(np.stack(embeddings), axis=0)\n",
    "\n",
    "  else:\n",
    "    embeddings = model.encode(text, convert_to_tensor=True).numpy()\n",
    "\n",
    "  return embeddings\n",
    "\n",
    "def outlier_cutoff(dataframe:pd.DataFrame, col:str, low_quantile:float, high_quantile:float):\n",
    "  \"\"\"\n",
    "  Filters the data based on the quartiles of given column.\n",
    "\n",
    "  Parameters:\n",
    "  - dataframe (pd.DataFrame): The dataframe that includes column which wanted to be filtered.\n",
    "  - col (str): The column that wanted to be filtered based on the quartiles.\n",
    "  - low_quantile (float): Low limit of the quartile of given column.\n",
    "  - high_quantile (float): Up limit of the quartile of given column.\n",
    "\n",
    "  Returns:\n",
    "  pandas dataframe: representing remaining values between the specified quartiles.\n",
    "  \"\"\"\n",
    "\n",
    "  return dataframe[(dataframe[col]<dataframe[col].quantile(high_quantile)) & (dataframe[col]>dataframe[col].quantile(low_quantile))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "\n",
    "\n",
    "df2[\"Tokenized_Chorus\"] = df2[\"Chorus\"].apply(lambda text: clean_lyrics(text) if pd.notna(text) else text)\n",
    "df2[\"Tokenized_Chorus\"] = df2[\"Tokenized_Chorus\"].apply(lambda x: x.replace(\"*vocalizations*\", \"\").strip() if pd.notna(x) else x)\n",
    "df2[\"Tokenized_Chorus\"] = df2[\"Tokenized_Chorus\"].str.rstrip(\"Embed\")\n",
    "df2[\"Tokenized_Chorus\"] = df2[\"Tokenized_Chorus\"].apply(lambda text: re.sub(r'Contributors|Lyrics|Contributor', '', text) if pd.notna(text) else text)\n",
    "df2[\"Tokenized_Chorus\"] = df2[\"Tokenized_Chorus\"].apply(lambda text: \" \".join(tokenizer.tokenize(text.lower())) if pd.notna(text) else text)    # Regex Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHORUS EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading pretrained sentence transformer embedding model. 'all-mpnet-base-v2' is used for Sentiment Analysis, while 'all-MiniLM-L6-v2' is used for Topic Modeling.\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "max_seq_length = embed_model.max_seq_length\n",
    "max_seq_length      # maximum sequence length of pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Texts: 100%|██████████| 9903/9903 [08:26<00:00, 19.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time : 8.43565754890442 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting embeddings of all choruses.\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "overlap=5\n",
    "model_embeds_dimension = embed_model.get_sentence_embedding_dimension()\n",
    "embeds_arr = np.empty(shape=(len(df2), model_embeds_dimension))\n",
    "\n",
    "for i in tqdm(range(len(df2[\"Tokenized_Chorus\"])), desc=\"Embedding Texts\"):\n",
    "  text_embedding = text_to_embeds(embed_model, df2[\"Tokenized_Chorus\"][i], max_seq_length, overlap)\n",
    "\n",
    "  embeds_arr[i] = text_embedding\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Process Time : {(end_time-start_time)/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving chorus embeddings and the final version of chorus data.\n",
    "np.save('Embeds_Chorus_20240312.npy', embeds_arr)\n",
    "df2.to_csv(\"Chorus_Data_20240312.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
